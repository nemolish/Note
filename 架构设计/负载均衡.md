一、负载均衡的概念

1、系统的扩展方式：

       scale up：向上扩展
    
       scale out：向外扩展

2、集群类型：  LB（Load Balancing）、HA（high availability）

3、LB集群的实现

              硬件：F5、Redware
    
              软件：lvs、haproxy、nginx

4、基于工作的协议层划分：

       传输层：
    
       Lvs：工作在内核模块中
    
       HAProxy：

1.mode tcp，如果工作在应用层只能调度http协议，如果基于tcp协议它能够调度https，mysql等常用的tcp协议

2.haproxy只是模拟tcp协议，因为tcp协议工作在内核当中，而haproxy属于应用程序工作在第七层，是工作在某个套接字上的应用程序

应用层：haproxy，nginx

从负载均衡设备的角度来看，分为硬件负载均衡和软件负载均衡：

硬件负载均衡：比如最常见的F5，还有Array等，这些负载均衡是商业的负载均衡器，性能比较好，毕竟他们的就是为了负载均衡而生的，背后也有非常成熟的团队，可以提供各种解决方案，但是价格比较昂贵，所以没有充足的理由，充足的软妹币是不会考虑的。

软件负载均衡：包括我们耳熟能详的Nginx，LVS，Tengine（阿里对Nginx进行的改造）等。优点就是成本比较低，但是也需要有比较专业的团队去维护，要自己去踩坑，去DIY。

从负载均衡的技术来看，分为服务端负载均衡和客户端负载均衡：

服务端负载均衡：当我们访问一个服务，请求会先到另外一台服务器，然后这台服务器会把请求分发到提供这个服务的服务器，当然如果只有一台服务器，那好说，直接把请求给那一台服务器就可以了，但是如果有多台服务器呢？这时候，就会根据一定的算法选择一台服务器。

客户端负载均衡：客户端服务均衡的概念貌似是有了服务治理才产生的，简单的来说，就是在一台服务器上维护着所有服务的ip，名称等信息，当我们在代码中访问一个服务，是通过一个组件访问的，这个组件会从那台服务器上取到所有提供这个服务的服务器的信息，然后通过一定的算法，选择一台服务器进行请求。

二、三大主流软件负载均衡器对比(LVS、Nginx、HAproxy)

1、LVS：

1. 抗负载能力强，性能高，能达到F5的60%，对内存和CPU资源消耗比较低

2. 工作在网络4层，通过VRRP协议(仅作代理分发之用)，具体的流量是由linux内核来处理，因此没有流量的产生。

3. 稳定，可靠性高，自身有完美的热备方案(Keepalived+lvs)

4. 不支持正则处理，不能做动静分离；但应用范围比较广，可以对所有应用做负载均衡

5. 支持多种负载均衡算法：rr(轮询)，wrr(带权轮询)、lc(最小连接)、wlc(带权最小连接)

6. 配置相对复杂，对网络依赖比较大，稳定性很高。

7. LVS工作模式有4种：

(1) nat 地址转换

(2) dr 直接路由

(3) tun 隧道

(4) full-nat

2、Nginx：

1. 工作在网络7层，可以针对http应用做一些分流的策略，比如针对域名，目录结构

2. Nginx对网络的依赖较小，理论上能ping通就能进行负载功能

3. Nginx安装配置比较简单，测试起来很方便

4. 也可以承担较高的负载压力且稳定，nginx是为解决c10k问题而诞生的，一般能支撑超过1万次的并发

5. 对后端服务器的健康检查，只支持通过端口来检测，不支持通过url来检测

6. Nginx对请求的异步处理可以帮助节点服务器减轻负载压力

7. Nginx仅能支持http、https和Email协议，这样就在适用范围较小。

8. 不支持Session的直接保持，但能通过ip_hash来解决。对Big request header的支持不是很好。

9. Nginx还能做Web服务器即Cache功能。

10. 支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、Ip-hash（IP哈希）

第6点补充：

squid同步处理：浏览器发起请求，而后请求会立刻被转到后端，于是在浏览器和后台之间就建立了一个通道。从请求发起直到请求完成，这条通道都是一直存在的。

nginx异步处理：浏览器发起请求，请求不会立刻转到后端，而是请求数据(header)先收到nignx上，然后nginx再把这个请求发到后端，后端处理完成后把数据返回到nginx上，nginx将数据流发到浏览器。

使用异步处理的好处：

1. 假设用户执行一个上传文件操作，因为用户网速又比较慢，因此需要花半个小时才能把文件传到服务器。squid的同步代理在用户开始上传后就和后台建立了连接，半小时后文件上传结束，由此可见，后台服务器连接保持了半个小时；而nginx异步代理就是先将此文件收到nginx上，因此仅仅是nginx和用户保持了半小时连接，后台服务器在这半小时内没有为这个请求开启连接，半小时后用户上传结束，nginx才将上传内容发到后台，nginx和后台之间的带宽是很充裕的，所以只花了一秒钟就将请求发送到了后台，由此可见，后台服务器连接保持了一秒。同步传输花了后台服务器半个小时，异步传输只花一秒，可见优化程度很大。

2. 在上面这个例子中，假如后台服务器因为种种原因重启了，上传文件就自然中断了，这对用户来说是非常恼火的一件事情，想必各位也有上传文件传到一半被中断的经历。用nginx代理之后，后台服务器的重启对用户上传的影响减少到了极点，而nginx是非常稳定的并不需要常去重启它，即使需要重启，利用kill -HUP就可以做到不间断重启nginx。

3. 异步传输可以令负载均衡器更有保障，为什么这么说呢？在其它的均衡器（lvs/haproxy/apache等）里，每个请求都是只有一次机会的，假如用户发起一个请求，结果该请求分到的后台服务器刚好挂掉了，那么这个请求就失败了；而nginx因为是异步的，所以这个请求可以重新发往下一个后台，下一个 后台返回了正常的数据，于是这个请求就能成功了。还是用用户上传文件这个例子，假如不但用了nginx代理，而且用了负载均衡，nginx把上传文件发往 其中一台后台，但这台服务器突然重启了，nginx收到错误后，会将这个上传文件发到另一台后台，于是用户就不用再花半小时上传一遍。

4. 假如用户上传一个10GB大小的文件，而后台服务器没有考虑到这个情况，那么后台服务器岂不要崩溃了。用nginx就可以把这些东西都拦在nginx上，通过nginx的上传文件大小限制功能来限制，另外nginx性能非常有保障，就放心的让互联网上那些另类的用户和nginx对抗去吧。

用异步传输会造成问题：

后台服务器有提供上传进度的功能的话，用了nginx代理就无法取得进度，这个需要使用nginx的一个第三方模块来实现。

第8点补充：

Nginx upstream支持的分配策略及原理：

1. 轮询(默认)：每个请求按照顺序逐一分配到不同的后端服务器。如后端服务器down掉，就切换到另一台并剔除down的后端主机

2. weight：指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。

3. ip_hash：每个请求按照访问ip的hash结果分配，不同ip的请求被分配到后端不同的服务器上，可以解决session的问题。

3、HAProxy:

1. 支持两种代理模式：TCP（四层）和HTTP（七层），支持虚拟主机；

2. 能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作

3. 支持url检测后端的服务器出问题的检测会有很好的帮助。

4. 更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现

5. 单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。

6. HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。

7. 支持负载均衡算法：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie）

8. 不能做Web服务器即Cache。

三大主流软件负载均衡器适用业务场景：

1. 网站建设初期，可以选用Nginx、HAProxy作为反向代理负载均衡(流量不大时，可以不选用负载均衡)，因为其配置简单，性能也能满足一般业务场景。如果考虑到负载均衡器是有单点问题，可以采用Nginx+Keepalived/HAproxy+Keepalived避免负载均衡器自身的单点问题。

2. 网站并发到达一定程度后，为了提高稳定性和转发效率，可以使用lvs，毕竟lvs比Nginx/HAProxy要更稳定，转发效率也更高。

注：nginx与HAProxy比较：nginx只支持七层，用户量最大，稳定性比较可靠。Haproxy支持四层和七层，支持更多的负载均衡算法，支持session等。

衡量负载均衡器好坏的几个重要的因素：

1. 会话率 ：单位时间内的处理的请求数

2. 会话并发能力：并发处理能力

3. 数据率：处理数据能力

三、中间件

中间件是在操作系统功能范围外为应用提供服务的多用途软件。任何位于内核和用户应用之间的软件都可以是中间件。中间件不提供传统应用的功能，而是将软件与其他软件衔接。由于中间件能够让数据从一个应用流动到另一个中，因此把它比作输水管最为贴切。

中间件就是程序中可织入的，可重用的，与业务逻辑无关的各种组件。

中间件(middleware)是基础软件的一大类，属于可复用软件的范畴。

顾名思义，中间件处于操作系统软件与用户的应用软件的中间。

中间件在操作系统、网络和数据库之上， 应用软件的下层，总的作用是为处于自己上层的应用软件提供运行与开发的环境，帮助用户灵活、高效地开发和集成复杂的应用软件。

在众多关于中间件的定义中，比较普遍被接受的是 IDC 表述的：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和网络通信。

分类：数据访问中间件，远程调用中间件，消息中间件，交易中间件，对象中间件。

举例：

1. RMI (Remote Method Invocations, 远程调用)

2. Load Balancing(负载均衡，将访问负荷分散到各个服务器中)

3. Transparent Fail-over(透明的故障切换)

4. Clustering(集群 , 用多个小的服务器代替大型机)

5. Back-end-Integration(后端集成，用现有的、新开发的系统如何去集成遗留的系统)

6. T ransaction 事务(全局 / 局部)全局事务(分布式事务)局部事务(在同一数据库联 接内的事务)

7. Dynamic Redeployment (动态重新部署 , 在不停止原系统的情况下，部署新的系统)

8. System Management(系统管理)

9. Threading(多线程处理)

10. Message-oriented Middleware 面向消息的中间件(异步的调用编程)

11. Component Life Cycle(组件的生命周期管理)

12. Resource pooling (资源池)

13. Security (安全)

14. Caching (缓存)

四、cookie和session

        1、Cookie是服务器存储在本地计算机上的小块文本，并随每个请求发送到同一服务器。 IETF RFC 2965 HTTP状态管理机制是一种通用的cookie规范。 Web服务器使用HTTP标头将cookie发送到客户端。在客户端终端，浏览器解析cookie并将其保存为本地文件，该文件自动将来自同一服务器的任何请求绑定到这些cookie。
    
        具体来说，cookie机制使用一种在客户端维护状态的方案。它是客户端会话状态的存储机制，他需要用户打开客户端的cookie支持。 Cookie的作用是解决HTTP协议中缺少无状态缺陷的问题。
    
        2、session会话机制是一种服务器端机制，它使用类似于哈希表（可能还有哈希表）的结构来保存信息。
    
        当程序需要为客户端的请求创建会话时，服务器首先检查客户端的请求是否包含会话标识符（称为会话ID）。如果包含它，它先前已为此客户端创建了一个会话。服务器根据会话ID检索会话（无法检索，将创建新会话），如果客户端请求不包含会话ID，则为客户端创建会话并生成与会话关联的会话ID。 session id应该是一个既不重复也不容易被复制的字符串。会话ID将返回给客户端以保存此响应。
    
        3、Session是保存在服务器上的数据结构，用于跟踪用户的状态。此数据可以保存在群集、数据库、文件中。
    
        Cookie是客户端存储用户信息的机制。它用于记录有关用户的一些信息，是实现会话的一种方式。